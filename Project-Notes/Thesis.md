It could be argued, now, more than ever, that data is the central pillar on which the modern world rests upon. Everything from critical energy and food systems, supply chains that keep as warm and fed, the games and television shows we consume are created, implemented, and maintained using a data-first approach. The reasons are varied of course: in the case of television, data allows for greater strategic planning, creating experiences which target a key demographic, with a certain spending habit to best extract value, by plying these groups with the shows they want to watch. In the healthcare field, data allows medical personnel to tackle key problems that might lead to policy changes: the battle against obesity, high blood pressure, diabetes and heart diseases are all waged using a data-driven approach: Find connections between certain ailments, cluster effects and propensity to occur due to the demographics of a region. 
The digital advent that has occurred over the last two decades has done nothing but accelerate this process, creating vast repositories of information, mostly without concern for the implications on the assumed right to privacy. The effort to acquire data, especially at the consumer level, has spawned organizations whose entire purpose is the acquisition of individual data, to sell to companies who wish to target consumers with ads based on their taste, conveyed through the information collected by technology and social media sites like Google, Facebook, Instagram, Amazon, and so on. And while there is an appropriate concern for the implications of such mass data mining, it can also eb said that the benefits have been immense: the creation and redefinition of entire fields such and the roles within them (Data Scientists, Analysts and Engineers) and the economic benefits and scientific advances that it has conferred being chief amongst them.
There are no fields that hasn’t been altered by the ascent of the big data age: Data in sports has always held intriguing potential, for its ability to look beyond the action on the field and unlock potential within individual players, teams, and organizations with the long-term goal of achieving greater successes, building dynasties, or even returning to relevance. Some Basketball teams within the National Basketball Association, over the course of the last two decades have taken it upon themselves to adopt an increasingly data-driven and statistical approach to the game of basketball, innovations made possible by new innovations in computer vision, software, and hardware engineering. Franchises within the league have taken it upon themselves to building new software platforms that take the wealth of visual and numerical data generated to build new models that have informed coaching decisions. 
Principle examples of this mode of thinking within the league have been championed by the San Antonio Spurs, Golden State Warriors and Houston Rockets, moving away from a heavier isolation and post-game heavy style of offense, to 3-and-out, rim running style prioritizing 3-point shooting as it has a higher expected value per attempt, and close range lay ups for higher frequency of point generation and second chance scoring opportunities. These insights were made dude to the new statistical approach of viewing the game whereas prior generations of coaches and players relied on the individual talents of star teammates and direct coach-led offensive schemes to generate scoring opportunities.
All these innovations in sports (In our case the game of basketball) are possible to a mix of hardware and software innovations that have taken the great many tables of data produced by scorekeepers over the history of the game, to provide tangible insights to drive the NBA forward. For this thesis, I have looked at the tools, websites, and software available to NBA fans who might lack the analytical or statistical skill to breakdown tables or lack of access to the same software that NBA franchise use to create their insights.
	 Aims and Objectives.
The goal of this projects is to create an MVP (minimum viable product) web application with modules capable of:
	Loading information about NBA players and teams
	Dynamically generating sortable tables of basketball statistics
	Allowing these tables to be used to create Data visualisations
	These visualisations need to be saveable to a user account for further editing or downloadable to Hard disk.
	This Functionality necessitates the creation of a login system to allow enable the ability to edit and retrieve visualisations created. 
Achieving this would require a comprehensive review of the various Software tools available to us: Programming languages, web frameworks and third-party application programming interfaces (APIs). The MVP is the lowest level deliverable required to achieve some the desired goal of allowing users to create visualisations on basketball statistics. However there also exist some higher-level goals for this project:
	The creation of a statistical engine on the web platform to conduct various statistical tests on the Data.
	Animation of Play-by-Play and player tracking Data, visualising game action that leads to scoring events. 




 
	Background and Context
Prior to any discussion or consensus on the development of the application, its important we ground ourselves in the historical background of the NBA and the use of statistics and data over the course of said history. Its also important to note the effect data and its visualisation has regarding the storytelling within the confines of the NBA. Furthermore, its crucial to understand the user of this app and the state of the field regarding the other tools and websites that may or may not facilitate some of the functionality that our application strives to accomplish. 
	The User
There is significant importance in creating an application that suits the needs of its users, however there is some base knowledge of the game of basketball required to fully appreciate the use case for this application. Therefore, this isn’t an app made for the public, but those with a slightly more nuanced view of the game, starting with the more casual fans to those enthusiasts with a desire for a more analytical understanding of the game of basketball, creating, and forming narratives from the data and visualisations created within the application. These fans can be found in great multitude on the internet, frequenting forums, and chat rooms, connecting with each other from across the world, a testament to the global reach and appeal of the NBA. One of the largest online communities in which basketball debate takes place is the Reddit community r/NBA. Reddit, one of the most visited websites in the world, has many community subreddits, catering to the many interests’ people have, with the NBA subreddit being the second most subscribed to sports subreddit, numbering 4 million with 10s of thousands of daily readers. Online engagement with these fans and NBA watchers is the demographic that would best represent the type of user the application is targeted at. 
 
	Context on the NBA
The NBA, if anything, could be considered a game of superstars. In few other team games is it possible for one star to lift their team from the doldrums of mediocrity to championship heights. There are palpable effects on stadium income and game attendance when a superstar is present vs when it’s absent, Kaplan estimates a 7.25% decrease in ticket prices, which in the case of an injured star, is a loss that can compound over the course of a season resulting in ticket revenue losses in the millions. 
Therefore, regardless of the various evolutions that have occurred since the NBA’s beginnings, from the increasing sophistication of on-court play, rule changes, game management, personnel training, and monetary valuations, the adage that basketball is a game of superstars holds true. It's through this veneer that we can divide the eras of the sport, and how the analysis of basketball has changed as a result. It’s important to understand the history of the NBA to some extent because it best explains 


	The Classical Era
The early era of the NBA could be counted as a period encompassing the founding of the NBA to the establishment of the three-point line. This was invariably the era of the big men: Towering centers who ruled the game from the post or under the basket. Arguably the leagues first true superstar, George Mikan dominated the earliest era, towering over his competition and leading his franchise, the Minneapolis Lakers, to five championships in 6 seasons, the leagues first dynasty. Bill Russell was the leader and defensive anchor of the greatest dynasty in sports history winning 11 championships from 1956 to 1969 and 5 Most Valuable Player awards during that Span. Wilt Chamberlain and Kareem Abdul-Jabbar, immense dynamos on offense and defence, setting records that stand till this day. While there was no shortage of excellent perimeter guards or forwards such as Oscar Robertson, Elgin Baylor and Jerry West, all hall of famers and NBA legends, this was in arguably the era of big bruising 7-foot players. This fact is represented in the awards handed out during the classical era: from its inception to 1979 the NBA’s MVP Award was awarded to a center 20 times, whereas guards and forwards combined for 4 during that same span. 
It’s in this era where we can see the effect a superstar can have on league policy. Mikan’s overall greatness forced rule changes that helped define the current state of the game, Firstly the advent of the shot clock in the aftermath of the Minneapolis Lakers versus Fort Wayne Pistons in 1950 led to the lowest scoring game in league history. The 24-second shot clock was an innovation that led to faster pace of play. The other innovation that could be attributed to the dominance of superstars is the creation of the “key”, the expanding the space around the hoop, drawing it out further to limit the scoring potential of post dominant players like Chamberlain, Mikan and Russell. Goldsberry directly attributes the current lane size to Chamberlain, as well as the concept of “offensive goaltending” and free-throw rules. 
While the classic era laid down the foundation for the current game regarding ruleset and player impact, it was a rather weak time for the games statistical timing. The game only officially counted core stats, points, total rebounds, assists, field goals attempted and made, free throws attempted and made as well as personal fouls. Blocks and steals weren’t counted until the 1973-74 season, the 28th in NBA history. Advanced statistics and analysis weren’t yet in vogue. 

	A Transitional Era (1980s and 2000s)
The advent of the three-point line, a holdover from the American Basketball Association (ABA) which had recently merged with the rest of the NBA, marks the dawn of the games modern age. While all save the most legendary players of the classical era have had their careers diminished by time, it’s from this point forward that the NBA’s superstars become cultural mainstays. This era saw the rivalry between Erving “Magic” Johnson and Larry Bird redefine the NBA of the 80s, against the backdrop of racial tension in America, and reintroduce the game to America, after 70s troubled by on-court violence, start-up leagues and drug issues. The 80s also introduced Michael Jordan, drafted with the second pick to the Chicago Bulls, who in the 90s would become the greatest of all time leading his Bulls dynasty to 6 NBA Championships in 8 attempts. Other notable superstars during the modern period would include Tim Duncan, Shaquille O’Neal, Kobe Bryant, Tracy McGrady, Vince Carter and Dirk Nowitzki all of whom would emerge in the later 90s and early 2000s. This period saw the intense internationalisation of the game, and an increase global appeal, driven again by the superstars of the league. 
This era sees the acceleration of the stylistic shift induced by the creation of the three-point line, moving away from under-the-basket, post centric style, allowing smaller and more ranged based players to shine, utilizing mid-range and three-point shots. The biggest motivator of this shift, as always are the popular stars that excelled at this type of shot profile. Michael Jordan’s sheer marketability, popularity, and style (a style that epitomized the aforementioned stylistic shift) meant that his on-court tendencies where emulated by the likes of Bryant, McGrady and Carter, and to a smaller extent Nowitzki. However, the game still had a place for offensively and defensively skilled big men in Duncan, Garnett and O’Neal. 

	Development of the Analytics Field in Basketball  
While advanced analytical perspectives emerged over the course of NBA history, the movement as we know it was deeply influenced by developments made in baseball, the field of sabermetrics and by the Oakland Athletics, a team that ushered in a data driven approach to their own game, leading to a record 102-win season in 2002 one of the lowest salaries in baseball, by picking up undervalued and underutilized players. Terner notes baseball’s owns sabermetric approach to constructing a team was crucial to the early work on basketball metrics written in the early 2000s. 
Dean Oliver’s Basketball on paper initially moved the needle away from per game statistics to that of a pace-oriented approach, how much could be accomplished in a set number of possessions, or set number of minutes, such as per 50 possessions of per 36 minutes. Oliver also pioneered the four factors: data driven axioms that correlate to a higher chance of winning. He created values such as turnover rate, effective field goal, offensive rebounding rate and free throw rates, which all trend higher on winning teams, and applied relative weights on each of the factors so they can a raw percentage chance of determining success. These factors are used by team front offices to determine relative performance against opponents, and as part of drafting strategies. 
 Another early pioneer, John Hollinger, introduced a new statistic that sought to estimates a player overall impact on the game. Player Efficiency Rating (PER), a metric that takes advantage of every variable in the box score to estimate players effectiveness. This was first of an emerging group of advanced statistics that seek to measure the overall player impact and efficiency, refining the methodology to resolve perceived flaws in pervious versions of prior performance statistics. By 2009, there was a consensus around the NBA that deemed that better tools where needed for cogent analysis of players whose box score stats, and hence box score derived analytics where subpar, yet held significant influence over the outcomes of games played. This realisation helped speed up the development on team statistical departments when Roland Beech, a stats guru 
 Examples of the increasing growth of the NBA analytics movement include the emergence of new personalities such as Ben Taylor, author of Thinking Basketball, Kirk Goldsberry, NBA Analyst, and author of Sprawlball. 
Beyond the numerical and statistical advances made over the earlier parts of the 2000s, a significant driving force of the current analytics movement is the dawn of player positional tracking and the creation of play-by-play data derived from inputs from player tracking cameras. The NBA was the first sports league to include SportVU cameras in each of their stadiums (Post-2016 the NBA has since transitioned to Second Spectrum). The effect of this drove demand for data professionals to create new insights into offensive and defensive possessions, team flow and on-court tactical strategies. 
The biggest effect of the data revolution has been an immense acceleration of the stylistic shift mentioned in section 2.2.2. Teams like the “7-Second or less” Phoenix Suns and the 2013-14 San Antonio Spurs served as early signals of the near total elimination of post focused play into the more pass first, 3 point or layup oriented up-tempo offense. But the team who have perhaps showcased the most from an analytics-driven approach to basketball is the James Harden era Houston Rockets, whom, led by an early advocate of analytics in General Manager Daryl Morey, saw an era of consistent competitiveness, historic and record-breaking offensive production, and personal success for James Harden, culminating in the 2018 Most Valuable Player. 

	Fan, Team and Media reactions to the analytics movement. 
A quick note must be made on the cultural impact of the movement amongst fans, teams and media personalities within the sport as their so acutely connected. Data driven insights early on had a great deal of detractors. Historically speaking, the measurement impact or the quality of a player, whether good or bad, rested on a concept colloquially called the “eye test”, essentially a set of long held values within the NBA that a players quality rested on factors like “clutch gene” or grit or whether a specific player was a “baller”. Some feared that analytics would drive excitement out of the sport and that teams would simply implement strategies deemed most effective on paper. NBA legend and hall of famer Charles Barkley famously derided analytics, likening those who choose to look at the game from its perspective as talentless people trying to force themselves into the NBA ecosystem. 



	Project Uniqueness and Existing Applications
The idea of a sports-data website or app is not unique, especially in sport as popular as basketball. It’s something that’s been done to varying degrees of depth and professionalism. Seeing as there are two aspects to this project, the gathering and presentation of raw data, and that data’s visualisation and analysis, it stands that we must evaluate the state of the art of basketball applications to determine whether anything new is being proposed by building this application. The first aspect, the creation of tabular data regarding NBA statistics is common and well operated. Arguably the most important of these websites is the official NBA Statistics page. There we can find tables of data for every player, team and game reaching back to the origin of the NBA. These tables exist for both the basic and advanced stats generated by NBA play as well as shot location data that’s used to build its patented shot charts. Another example of this type of website is basketball-reference.com, sourcing its initial data from sport data APIS like SportRadar. It too provides the same view of data as the official NBA stats page, tabulated, here however the data is exportable in a .csv format for those with a deeper understanding of programs like Excel to build out graphs and tables. 
While there are other smaller applications that serve the purpose that both these two major sites represent or are equipped within a degree more of functionality (theScore also takes account of betting lines and digital communication between fans during live games) the second major section that our app represents, the visualisation and analysis of data is far less common. From a purely software-based perspective, there are few applications or websites freely open to consumers that over anything other than surface level comparison between player data and teams, and outside of shot charts, programmatically create visualisations of this data for consumption. Visualisations regarding NBA statistics are still mostly created outside of a web application using Excel, R, Python and Stata or some form of proprietary software not available to the average fan. This absence of easily accessible data is compounded by issues like the lack of official documentation of the official NBA APIs (stats.nba.com or data.nba.net) or lack of personal access to SportVU or Second Spectrum visual data that records NBA player actions of in the court. 
As such, the design space that this app is operating in is to create NBA data visualisations of player and franchise statistics using a web-based platform, is relatively unique even if it contains elements of other websites such as tables to select data for use or shot chart generation for export. Furthermore, the two major sites we looked at don’t offer the login/graph load and save functionality that is being constructed within our application.






	Data in the context of the NBA
 
 Figure 1: Los Angeles Lakers basic box score vs Milwaukee Bucks on the 17th of November 2021
The breakdown of data within the NBA stretches numerous dimensions. At the lowest possible level exists the box score, quantitative and discrete (in so far as it’s a numerical measure whose accuracy cannot be improved) data points that capture various game actions: scoring, rebounding, passing, stealing, or blocking the basketball, effectively serve as the base level of data regarding player performance. An increase in any of these values denotes a positive action taken by a player within the game, such as scoring to push your teams lead, or getting a steal or block to deny a potential scoring possession by the opposing team. Rebounds can go two ways, an offensive rebound resets the possession for the attacking team, adding time to the shot clock and allowing another attempt to score, whilst a defensive rebound ends the opposing team’s offensive possession and can often lead to a “fast break” a quick and hard to defend scoring opportunity.
Within the context of the box score there is also data types that indicate negative actions by players. Turnovers, either forced such as having the ball stolen or deflected, or unforced like bouncing the ball out of bounds, are negative actions that end a possession (a chance to score). Personal fouls, which lead to a game stop and can, if a certain number of fouls are drawn, mean that players on the opposing team can shoot free throws to accrue more points, effectively making a negative action a positive gain for the opposing team. The box score also encompasses scoring metrics based on shots taken and shots made for the three shot types: Field goals, three-point and free throw attempts. Other miscellaneous box score data points also include minutes played in a minute-second format (MM:SS) as well as plus/minus data point (+/-), which is 
Advanced statistical data then, is derived from equations performed on basic box score data, in combination of relative weights applied to the relevant statistics. Whilst the typical box score seeks to provide as single instance data point on the events that occur within a game, advanced box score statistics are an attempt by their creators, media personalities and fans to mathematically discern a player’s impact beyond counting stats. Therefore, whilst calculating a largely quantitative task, it also serves a descriptive, qualitative purpose. Examples of advanced stat formulations can be seen in the way we calculate Player Impact Estimate (PIE), which again takes advantage of the entire box score can be denoted below:
(PTS+FGM+FTM-FGA-FTA+DREB+OREB/2+AST+STL+BLK/2-PF-TO)/(TPTS+TFGM+TFTM-TFGA-TFTA+TDREB+TOREB/2+TAST+TSTL+TBLK/2-TPF-TTO)
This formula takes each players individual contribution to the game while dividing it by total game metrics. Beyond overall player impact, other advanced stats seek to provide significant insight into a specific aspect of the game where box scores stats fail to elaborate. Shooting in the NBA at the elementary box score levels are separated by shot categories with shots made divided by shots attempted, but advanced stats can offer deeper nuance and help curate a narrative on whether a player is particularly effective at scoring. True shooting percentage is an advanced statistic that considers every shooting statistic to measure overall shooting efficiency: 
TS%=PTS/(2(FGA+(0.44*FTA)))
The final type of data that is prominently utilised is spatial-temporal player tracking data. As mentioned in section 2.3, the NBA in the early 2010s installed various specialised cameras around NBA arenas to build exceptionally more detailed play-by-play data sets than the basic versions that started to appear in the early 2000s. modern player tracking allowed for a finer level of details when it came to move set classification. A score was no longer just a differentiation between a 2 point or 3 point shot but whether or not the two points where acquired by layup, dunk or mid-range jump shot, whether a three-pointer was on a “catch and shoot” where a player is ready on the 3 point line to immediately attempt a score  or a “pull-up three” where the ballhandler effectively attempts a shot with significant time on the shot-clock. Beyond move set classification, the player tracking era has been a boon to in-house analytics teams on analysing player decision-making and evaluating scoring scenarios due to the emergence of “expected possession value”. 
This concept was created due to on court location data, combined with an average weight applied to potential game actions that can ball handler can initiate. Macdonald further notes two important factors when estimating a potential game action, other players possess the same decision-making facilities vis-à-vis on court movement, the ability to get open to improve a team’s offensive profile during that specific attacking possession such as dropping your defender, setting a screen on the on-ball defender etc. It also worth noting that as the ballhandler and his teammates make decisions, their opponents currently on defence take actions that invariably decrease a possession’s value. This complements the second factor, that each potential action by the ball handler, his teammates and their opponents are modelled separately to create, and all this is therefore gives rises to secondary values derived from EVP. 
 
	Design Methodology and Development Considerations
Building a significant piece of software requires discussions on various aspects of the development process, from the approach taken for the design of the application, to details and tools that are planned for use within the process of development. 

	Approach to the development process
For success of this project, there must be some form the continuous iteration so that potential users can view and utilize the product and provide feedback. Therefore, a consistent alpha and beta version of the application must be made built using a agile process. An agile process, even when implemented by a sole developer, provides a clear feedback loop on application iterations, on what works correctly and whether they feel, as users, that the development requirements are being met. It also provides an avenue for constructive criticism, on what application features and components needs further iteration or if an adjustment must be mad (alteration or removal of certain requirements). 
To this end a target group of friends and family has been created to help keep the application grounded in the various requirements stated earlier in the introduction. And to this end engagement will include, viewing and critiquing major components and themes, user interface design and user experience issues such as visibility and accessibility. To do this, they will have access to a view of the application through localhost tunnelling or controlled demos over video conferencing technology like Zoom, Discord or Microsoft teams.  
	Design Philosophy
A quick note should be made on our broader design philosophy. User (or human centred design) is a thought process that embraces that idea that humans themselves are all designers and requires designers to empathise with problems faced by humans in the design space whilst utilizing them during the development process, beyond just documenting their reaction and thoughts on the state of the application and product use, such as involving them in the iteration process, brainstorming and prototyping. This also occurs while focusing on delivering the general set of agile principles beyond planning and design, which is completing development and the feedback loop that allows for the iterative process to take place. The merit of human centred design is obvious, that the future user should have significant influence is given seeing as this is a product in part designed for general use by basketball fans seeking a multitude of services from the app: A quick lookup of current NBA players an easy visualisation system for stats in the browser. There, however, exists some merit in approaching this from a purely product perspective due to the assumed difficulty that is apparent in some component design, namely the creation of a statistical engine for deeper mathematical view on the relationship between NBA stat variables. The case for every user being involved in a design process is weakened when there is a disconnect between their induvial (or even collective) vision for the application, and the technical skill and knowledge of the engineers having to implement it. Essentially, the application has to be grounded in a shared reality. 
Secondly a broader take on the implementation of agile processes within the scope of our project are in order. There exists a range of design approaches that take advantage of the iterative nature of agile development, there are also flavours of agile development that should be considered. One of particular interest that fits this project well is the use of Feature-Driven Development (FDD). A react app is defined by the components that comprise it, hence it cannot be considered a monolithic structure with mass interdependency in all aspects. The component-style structure of react apps lends itself to focused periods of development where an active feature is planned, designed, developed, and tested both independently and by focus group, looking for both positive and constructive feedback. Therefore, in a hypothetical app structure where we have a component dedicated to finding players which includes functions such as: 
	Pulling data from an Application Programming Interface (API) and saving it as state
	Dynamically present the data using higher order functions
	Allows you to filter the presented data using a select field,
Keying each major view and the component involved in the building of said view could, foreseeably be done well in an FDD format. Other benefits include rapid adaptability to the changing design requirements, per the iterative format and reliance on user feedback in the agile design process. 
 There are of course some detrimental elements to the use of any agile method. In the case of this application’s development, one such detriment that should be mitigated against alludes back to the point made on human centred development: which is the need to include users at every stage of the development process, meaning less time building the project and more time managing feedback and opinions created by the presence of users. This overreliance on the processes that deliver information on the whether the application is meeting requirements does imply a certain disregard to the product design and architecture processes that help ensure an applications overall design cohesion. 
Agile also presents a certain risk to overall application cohesion. Its nature of rapid, iterative design changes can mean shortcuts taken which in app development means external libraries that shorten development time. Thus, any change from the iteration process that means suggests a removal or adjustment of certain components could mean time spent refactoring and rebuilding already existing functionality using a newer library. Effectively there may be a need to account for the trade-off between refactoring old components and the development of new functionality. It also serves to remind us of the potential for exploding complexity that might occur due to choosing prebuilt and documented solutions to some issues (such as data fetching, of which there are multiple approaches that will be discussed in detail further below). 


	App Design and Architecture
From a design perspective, there is merit in constructing a view on how a user will use the application, a user journey through different web views and components, using paper and digital mock-ups of the website as a test bed for users. The architecture of a web application and page flow can be demonstrated in multiple different ways: A top down, stack driven architecture that displays the actual tools and request flow in and out of the frontend view through the middleware to the backend. Optionally, we can evaluate architecture in more detail on a component level, seeing what data is fetched and where. 
	Initial App Design.
Design is one of the few areas where the agile process has its most influence, guiding an application from mock-up to MVP to a production ready webpage highlights the effectiveness of the iterative process. The images below present the core web views and components required to achieve construct an MVP product. 
The mock-up details the application flow from the perspective of a parent view to that its child component. The first details the player section flow: 
 
Figure 4: Player Section Mock-up
Page navigation is rooted in the nav-bar component which routes to the other staging points within our application. The navigation from the player finder view to the player detail’s view is predicated on the selection of either a prerendered player card (an accessibility tool for those who lack knowledge of NBA athletes) or the search bar which contains all current NBA players.
The same view flow can be established for team finder to team details flow, from the nav-bar to the team cards containing core team details (name, conference, wins and losses), then leading to the team details page, with broader information, team roster with stats via a table and previous games log. 
The other components (Analysis, Gloss is distinct in the fact that its accessed directly by the nav-bar and is comprised of one smaller card element containing the settings to which to construct a visualisation with the ability to add and remove players, toggle stats for direct comparison using a line chart (for the MVP). The larger card is responsible for the rendering of the chart to the view. 




	Core Programming Languages and Tools
Software development is replete with a variety of tools that can enable the production of any sort of application or data analysis/ visualisation. The advantage of choice allows us to analyse the various technology stacks and whether the tools within them can allow us to construct what our application needs. As our application is primarily web and desktop based, we can leverage features like more powerful computing solutions and larger screens to create a strong, visually appealing web application. This section will be concerned primarily with the core tools/ecosystems that will be critical to development. Some minor packages will be discussed further in the section 4 where the discussion of the application construction takes place. 
	Frontend Development
ReactJS serves as the frontend library of choice here. Built and maintained by Meta (formerly Facebook), its declarative, making it easier to read and write code. React also benefits from the use of a virtual document object model (DOM), which over the conventional DOM, has significant memory, speed, and performance benefits over traditional HTML and the standard DOM. ReactJS utilizes JSX, or JavaScript Extensible Markup Language, allowing the co-existence of HTML code snippets and JS syntax to help produce user interface elements. ReactJS’s largest advantage over the traditional static HTML/CSS combination is it allows the creation of reusable components in which we can pass parameters called “props”, that help build further component functionality. 
While react is effective as a UI library it is relatively barebones compared to fully fledge frameworks like AngularJS; as such we can take advantage of the JavaScript toolchain, Node Package Manager (NPM) to add new libraries that help implement new functionality such as React Router, which allows for dynamic page routing around the application, and keeping some views and components unrendered if authentication requirements are not met. Other libraries offer pre-built components such react-bootstrap, which allows for responsive elements taken from the standard bootstrap library to be used in a React context. While this functionality isn’t limited to React apps, the advantages of this is far quicker MVP creation and turnaround on feature creation, something that suits the agile approach application development is taking. 
These react tools are a significant element of this application as many are involved in the construction of the various components that comprise the app.
	React Router, a declarative routing library that allows for the linking of our various components together without refreshing and is key in the construction of any react application. 
	Ant Design, another component library like react-bootstrap, but with a broader focus on sleek design templates
	React-Table, a utility class for the design and implementation of robust tables using custom hooks provided by the library

Beyond the interface scaffolding and UI building properties of React, we will be taking advantage of Cascading Style Sheets to customise the look of our components. The earlier project proposal suggested the use of SASS (Syntactically Awesome Style Sheets) but it has been an unnecessary addition to the project. 

	Charting Libraries.
An oft repeated central objective of this application is the dynamic visualisation of data, a task that is served by frontend components. There are two options, D3.js and Charts.js. 
D3.js is a library designed for the presentation of data on the web through binding data to the DOM, and the application of graphical transformations to create unique graphs. As such, d3 doesn’t follow a template method, where certain types of visualisations are already created, therefore any type of visualisation must be defined with client-side code, making it more verbose but far more powerful than a templated solution. D3, being purely client-side, eliminates the need for back-end communication except in the case of data requests required to deal with data. There are however some nuances to using D3 inside of a React application. D3 targets the DOM but React apps are implemented through a virtual DOM, so D3 must interact with the virtual DOM through references to a virtualised JSX container element, which will serve as the building blocks of any visualisation created. 
Chart.js then, is a template driven charting library, that comes complete with 8 common graph types. It is inherently less powerful than D3. But its simpler implementations mean we can take advantage of props to transfer data to pre-built charting components to quickly render a new graph. There is also some DOM/Virtual DOM conflict between it and the react framework, but any compatibility issues are solved the wrapper library for chart.js.
So, two use cases emerge from both these charting libraries. Chart.js is suitable for a significant portion of our applications needs from simple graphs showcasing basic NBA counting stats, to two variable analysis of NBA player variables like three-point shots and three-point makes. D3 is far more suited to more complex or esoteric visualisation needs, in these cases building NBA shot charts, a visualisation that is uniquely different for every NBA player. 

	Backend Development
While frontend development in the case of this application is a relatively integrated affair, with a React app and JavaScript toolchain that makes adding required packages and libraries trivial, and a similar ecosystem all based around the same language, backend development is often more modular, with different services been required for different duties. Two set duties required of the application is data fetching which, can and is often carried out in the client side of an application, in this case requires a combination frontend/backend solution, through a request library. Secondly, application requirements require that the app must be able to login and save images over the internet, therefore we require a backend solution to this as well. As such, we have identified three services that need to be constructed for the goal of the proper functioning of this application. 
	Firebase Authentication and Database. 
The authentication layer of the application will be implemented with Firebase, a backend-as-a-Service (BaaS), utility to comes complete with hosting, security and database services and provides us with significant boilerplate code to hasten the creation of typically complex features like an authentication layer, which matches well with agile development philosophy. There was also an exploration of an express.js and mongo database approach to authentication that will be analysed in the implementation section. 
	REST APIs and Data Sources. 
Data as previously stated, is at the core of this project and sourcing it is of major concern to the backend implementation of this application. There are multiple REST APIs available for consumption by the application and while they each have their merits and drawbacks, I ultimately handled data using 3 core APIs. The REST protocol or the Representational State Transfer protocol is an architectural style for distributed media systems, that contains a uniform approach to the request and acquisition of data over a HTTP network. 
The first of the APIs we explored in the construction of this application was those located on the RapidAPI platform, API-NBA and Free NBA APIs. API-NBA offered endpoints on a lookup of current NBA players, and their performance through major statistics, as well as access to some media options (team icons and player headshots). Beyond these benefits however, they were scarce on many data points that would be required to build a robust data visualisation of any merit. They lacked detailed game logs (which as contains advanced statistical data) as well as play by play information, and as such while they may be beneficial for some presentational elements, they couldn’t truly anchor the data visual element of the application all too well.
The second major API considered for this application included the Sportradar NBA API. Sportradar, serving as the NBA’s official data partner, contains a host of powerful endpoints that included play by play data, and some location data, (important for the implementation of a shot chart visualisation). However, there were limitations. Large scale deployment requires thousands of API calls, and the Sportradar API only offered small, individual applications a trial that only permitted 1000 calls a month. Such rate limitations make it impractical to deploy. Beyond this there were some technical problems that would be elaborated upon during the discussion of the application development. 
The API that was selected for the core of this application, was the unofficial NBA API, maintained by the association. There are two resources that are published by the association: stats.nba.com and data.nba.com. Only data.nba endpoints are accessible within a web browser (in essence the same origin), while the other runs into cross site resource retrieval errors (another point to elaborate on during the discussion on development), which ensures that access from a client-side application is impossible meaning the requirement of the implementation of an API proxy, a service that acts as a ferryman between user requests and the API endpoints and queries results. (Exploration of the stats.nba API and its endpoints as well as the construction of an API proxy is a significant development topic that will be fully explored in the relevant section). Its important to note that while we are relying on API services to deliver some data, some will automatically be rendered from JSON built using web and API scraping, for the sake of simplicity or static presentational components. 

	Python Toolset. 
Python (and its ecosystem) are the last significant element of this applications stack. Python is an interpreted, object-oriented language that ubiquitous with data analysis and visualisation, but also provides frameworks heavily employed within the technology industry for web and API development. Its alongside JavaScript, allow for quick turnaround times on development and implementation cycles. Of the framework and libraries available within the ecosystem, Flask is a lightweight “micro” web framework to build backends and APIs, helping to simplify API request and response routing and dispatching, and possess the same philosophy of the react eco system, an inherently light tool that can be extended through additional packages. 

	State Management.
The complexities of modern web application development are accentuated by the significance of state management problems that arise whenever a relatively robust or data heavy component-based application is created. The concept of state itself is opaque, but within his context, it can be distilled into a simple premise: State is any data that helps shape in-moment behaviour of the application. 
Specific types of state can include communication state, which manages the flow of information to and from various services, which are yet to be completed, UI or application state, which is the state of component elements within an application, whether a certain component is selected, whether a form component like an input or select has any value and storing said value. There also exists session state, differentiating between who’s logged in and communicating with backend services such as databases or cloud storage to deliver the account linked to the login parameters passed in. 
While this list is not exhaustive of the types of state that exist, they are the core types of state that will require development control over. Therefore, state management as a whole is the task of ensure fidelity of state over time and through changes, ensuring that state read and writes (lookups and updates) are coherently and correctly handled and this is accomplished, in the Context of React, through a myriad of techniques, and frameworks.
As such for the purposes of this application, most application state can be handled using either React hooks, a newer feature of React 16 or the popular state management library, Redux and Redux Toolkit, which enables simpler code practices in setting up data stores and services to manage state across the application.
 
	App Architecture
The diagram of how each of the above components interact within the project is laid out below: 	

React Router and Redux encapsulate every component within the application, with Redux acting as a global store allowing for state to be passed to every component via react hooks, and the router allows page/view navigation within the application. 
API calls are managed 

	Application Development. 
This section concerns itself intricacies of the development process of the various components and views that make up the application. This section will also go over problems and alternate approaches I pursued to build key elements of this application that were phased out for another, simpler solution. 
	Sprint 1 - Environment Setup. 
The application architecture presented above requires the decoupling of the 2 major portions of this application. A decision was made that the first task should be creation of our base directories for both the flask API proxy server and react application base using the create-react-app command line interface (CLI) and to install the various dependencies required. 
The initial problems of installing Python for use for our proxy server served no problems however, a common issue exists with the installation of libraries in the base python directory for use. Sometimes integrated development environments are unable to detect their installation making calling them difficult. Hence the first major package required of this Sprint cycle was the use of venv, a library that creates a virtual environment for the python installation of your choice. This offers programmers granular control of what packages exist within this environment, which acts as almost a fresh installation of python, hence anything installed here doesn’t get installed at the overall system level, leading to less system pollution 
Secondly, packages in this environment are more easily retrieved than importing from packages from the system site level, which as before, occurred at the start of project. Finally, there exists the capability to freeze dependencies, due to the encapsulation of your packages, you can run a custom command to create a text file of every package used within a virtual environment and use that requirements.txt file to create those environmental conditions on any machines. 
In comparison, setting up the react application as previously stated was relatively simple, and only required the use of the create-react-app CLI, which auto installs some of the node modules, underlying libraries that power the react ecosystem. Its at this point we also install other key dependencies mentioned in section 3, using NPM, JavaScript’s, package manager.  

 
	Sprint 2 – Basic Frontend View and Navigation.
At the start of our frontend development process, target was to create the home page view as established in the initial mock-up, that comprised of the home landing page, as well as navbar and the page links situated within the navbar.
Folder Structure is a significant challenge in any application, even more so in a web application that separates down into distinct components each with their own logic, hence, the requirement of a separate component folder to build. With the discernment of the folder structure complete, building out the nav component and handling page navigation is simply a matter of invoking JSX elements within the react-router and react-router-dom libraries. To aid the creation of the navbar, the core views that comprise the entire app, such as the player and team sections, glossary and analysis views were created to serve to delineate the sections of the web application.  An index.js file was created to facilitate export of the components to the main app.js file which is responsible for the rendering of the entire web application. 






With this, instead of a list of imports from the components folder within our application, we can use destructing syntax introduced in the ES6 JavaScript version, to call the required imports in a single line such as shown below: 
 
Finally, to enable the actual change in view we introduce Routes, Route and Link components from our routing libraries, which facilitates this action. The routes element is an example of conditional rendering implementation, where the routes element will listen to the current URL of the react-app when its deployed and will only switch to the relevant component that’s present in a route child element when the URL matches. Initial work on the main app component used version 5 of the react-router and react-router-dom library, which used a switch element and nested component syntax, which was relatively verbose, the version 6 react-router library eliminated the need for a Switch JSX element with the introduction of the routes parent element to host routes elements inline with components.  
For general styling, initially, we started off with react-bootstrap which contains a flexbox-implemented grid system that can be manipulated to create styled, ordered layouts. The first use of this is the react-bootstrap container element which provides some automatic responsiveness to different screen sizes with the content inside adjusting accordingly, which can be paired with bootstraps row and column elements to shape content on the page and provide spacing between each sub element. Benefits of this approach, using the flexbox system, include being able to automate the flow of elements and use broad class types such as antd and reduce time spent on the design of a website, something that can be revisited when we need to. 
There are however downsides. Other options are natively supported by most browsers, whereas bootstrap elements and class attributes must be downloaded from the imported CSS stylesheet that comes with react-bootstraps installation (This same limitation is present within the ant design component framework). Furthermore, the grid system implemented using react-bootstrap is, as previously stated, implemented with flexbox, which only concerns itself with a unidirectional flow, meaning overall less control than a pure grid system. There are also elements of verbosity in approaching the use of bootstrap within an application, leading to crowded, repetitive code, that can’t be placed within your typical CSS class. 
In web development, positioning of elements is of critical important and there are several approaches I looked to use instead of the system offered by react bootstrap. The CSS Grid system, an explicitly defined grid with more granular control over the positioning of elements within our application was one that had strong appeal, but for an MVP, would require significant styling of every page, with more details to each element within the application. 
	Sprint 3 – Player and Team Finder Components.
The building of the player section was the first set of components that required use of the APIs to fetch player details, and the first that required us to take advantage of built in react state management features and the redux library to construct global API calls using react hooks. A list of the technical challenges to where present during this phase of the applications life cycle are:  
	Prebuilding card elements that contain some player information and redirecting to the relevant player details section
	Creating a searchable list of player names that correctly fetch their own details
	Constructing the first version of our API proxy to respond with the correct player data objects.
	An exploration of the data objects in a table format. 
	Managing API calls using either a HTTP request library or redux. 

	Player Finder
The first stage of the player finder view required the creation of pre-built card elements to encapsulate some player data, and to serve as links to their respective details page. This was done for two-fold reasons: preliminary testing that the link between the relevant player’s name and details work, and as an accessibility measure to those who lack knowledge of active NBA players but may recognize more popular players like Lebron James and Stephen Curry. 
To construct the player cards, the choice was made to take advantage of the ant design component library installed earlier. The data that helps create the card is one of three instances where we are not calling an API to build a component but rather a JSON array with objects that contain pertinent player information, such as name team and player ids. These arrays where created by scraping the Free-NBA API as well as the stats.nba API. Beyond this, assembling the card elements where trivial, it was a matter of using string interpolation to place the variables that represented values we wanted to display. Building card elements for each of the players within playerJSON document required the use of higher order JavaScript: the map function is heavily used within the application as we are handling a high amount of array data structures, that may contain object structures on player stats, or raw numerical statistics that need to be displayed. In the player finder component, the use of map takes each object structure and creates the card with the interpolated string calls taking the values from each object.
The image of the players is fetched using a URL that takes each players unique player id and retrieves their headshot. This is one of two URLs one that takes the unique ID from the free NBA API which is explicitly used for the 8 player cards that make up the front page of the player finder. The other URL takes the player id from our stats.nba API proxy which will be used for all other players used in the future. 
The functionality of map takes each object within an array and allows it to be transformed by extrapolating each value of out of the object: the JSON that informs the card details is as follows:  
Whereas the code that actual builds each card is feature below in Figure 5: 
 
The use of the Row and Col elements here is to provide structure to the cards and the CSS applied to the card is featured in the antd CSS file import that’s located in the base index.js file at the root of the source code. 
 

Finally, the goals of this sprint required that these cards serve as links to their respective details page. This required the creation of a new component view: Player Details and figuring out how to fetch the correct page view depending on the selected player. One of the features of react-router is the idea of URL parameters and the library provides a react hook that allows programmers to extrapolate URL parameters and save it to a variable within their code. For a parameter to save with the useParams hook, the new player details component must have a dynamic variable attribute. This was accomplished using colon syntax: the URL that identified the player details for that selected player would be: 

Link the cards to their respective page then is as simple as wrapping the generic card element created within our mapping function in a link that takes that player unique player id as so:  

This provides the link to the player details page using that person id (the name of the id in the object being rendered). 
 The result of our link setup leads and the positioning of the route element in the app.js file where our other routes are located, serve up this URL when the Stephen Curry card is selected: 


That URL parameter serves an important role in allowing us to use it within future API calls to grab player information and seasonal data. 
	Team Finder
Initially, much of the same logic used in the creation of the Player Finder view and components is like that used in the creation of our team finder component. The scraping of the free-NBA API was crucial in building the JSON array objects of team data, however, while some of the information on the player cards wouldn’t be outdated by the end of the season, much of the data gathered by the scraping of the certain team endpoints would be as an NBA season wore on, Hence the only thing projected is the team URL and name. The linking to its relevant team details page using a unique team id and wrapping the generic card element within our code, all remains the same. 
 
A while there is some visual appeal to the use of card elements to display top level team details as well as serve as links, the page was relatively bare of information. The was some struggle over the use of the API to keep information up due to breakages within the API calls, hence the stop gap of scraping the specific JSON objects from the API. 
This page was reworked to create a more tabular view of the teams separated out by the conference each team resides in.
 
	Sprint 4 – API proxy development 
The choice of using the python for the backend is for the API proxy came out of a desire to utilize an already existing API client library for the stats.nba.com endpoints, Swar Patel’s, nba_api.  It comes complete with many of the endpoints mapped and was developed with default values already set so that API calls would require a small amount of code, and that dynamic variables would be added as needed. It also has the advantage of being able to send response data through a variety of formats either as JavaScript Object Notation or as a data frame for manipulation with the many data libraries present in python.  
Constructing the API proxy was a relatively simple process as the fact that the API calls where prebuilt in the API package, the most significant task in this process is to shape the flow of data through fetching with an API request and giving out a response. 
Flask enables this functionality through a route creator and utilizing the requests library.
 
Figure 8 shows an example call, where we create an URI that identifies the underlying function, in this case is denoted by the @app.route syntax. This method also demonstrates added dynamic functionality using a query string, where the p_id variable is initialised by the whatever value is passed into the request identifier “player_id”. This p_id value is then passed into the API request, a pre response variable, to grab that players information and the res (response) variable is set the pre response value with a method applied to convert the response to JSON. This architecture is the basis for most of the API routes created within the proxy client. 
One significant problem that initially stalled progress on this element of our application was the cross-origin resource sharing (CORS) issues. CORS is a mechanism that allows one URL to request data from different URL, and this error occurs when a URL request violates the same origin policy enacted by browsers as part of their security measures. The resultant effect of trying to request a resource from our proxy, which is in effect just a gateway to the stats.nba.com API means that the same origin policy is violated.  Herein lies the second benefits of creating a proxy, control over the backend middleman that fetches the API requests enables the ability to send cross origin requests by downloading the flask CORS library that will enable requests to flow freely between the frontend client and the API via the proxy. 
 
	Player and Team Details Developments.
The player and team detail components offered the first opportunity to connect the backend proxy to the client. Firstly, as stated in section 4.3.1, the use of react router’s useParams hook allows the URL address to be destructured into its component parameters, containing the variables that make up the address. In this case, the player_id, a property of the player info that makes up each player card or serves as a key for that player’s name in the player finder dropdown list. 
The player id serves as the basis of page navigation and is the essential variable to bring up any players information through our API proxy. API calls in this application are managed in several ways, through the axios fetch library and using Redux Toolkit’s create API toolsets. Regardless of the approach taken within each specific component, whether its axios or redux based, they all connect to the same proxy and call the route their linked to through the API. While in development, both the react application and the API proxies are deployed to localhost (127.0.0.1) on different ports, to prevent cross connection. 
Axios’s approach to API calls is more in line with the standard fetch library syntax, directly passing in the resource URI and resolving the ensuing promise that occurs to retrieve your data. Redux Toolkit initially acts in the same fashion but allows for the attachment of middleware through the reducer.js file, enabling caching and cache timeouts to reduce resource calls. And while allowing the creation of API hooks, Redux also acts as a general state library for your entire application. Enabling redux functionality within the application requires, like react router, a root level encapsulation of the entire react app, which allows for custom redux hooks and global state to be used without the need for extensive prop drilling, a phenomenon where data is passed as parameters through the component tree to child component, but with the problem of passing state through components that don’t require it. The structure that allows for this is called a store, where all global state, and API hooks created by redux must live. 
For the purposes of building out the components that comprise the player details viewthe creation of 3 separate API calls were necessary. One of the core benefits of using the redux API, is the ability to define multiple endpoints within the same code structure and deploy them as react hooks (functions that possess the “use” prefix). The process involves creating an API “slice” which includes the declaration of the base URL, which is, within the development environment, localhost, and then using the query builder module, to automatically link the query to a hook. Following this process, creating a


The mechanics of controlling data and presenting API values is relatively simple. Liberal use of the useState react hook allows us to save distinct values returned from our respective API calls. One problem with API calls and saving their data to any variable or state mechanics is the fact that as there is a time delay (no matter how small it is) there is a chance at render time that the data is unavailable and as such state functions and variables that depend on the fetching of data end up as null or on defined, cause breaking changes within our UI. There are two potential resolutions to this issue. 
Firstly, all API calls are considered side effects within the react ecosystem, as such we can place the resource calls in a useEffect hook, designed to run code when state or prop changes within the application after all components are mounted to the virtual DOM. Setting state from an object value returned from within a side effect is the best way to guarantee a lack of undefined calls. 
The other method to ensure data flow is the use of optional chaining. The data being returned through the API calls are often deeply nested object values, hence the use of a chaining indictor, which in JavaScript is the question mark operator. This will throw an undefined response to any object values that are displayed until the data in the promise created by the asynchronous function is resolved during runtime, after which, the data will load, and values are updated within the DOM. Since we are making API calls in multiple different ways, its important to note that while we are declaring an asynchronous functions with our axios/fetch calls, react createAPI slices hooks are automatically asynchronous, without additional code.
	Table components.
Beyond presentational elements that are derived from resolved API data calls, the other major components in both the player and team detail views are the data tables, required by the application specs. The table components are built with the react-table package. The methodology for the construction of table components is twofold, sending in configuration details, a columns file and the stateful data of the items that need to be displayed, and the utilization of the react-tables hooks to build out the component. Firstly, the columns file is an array of objects with each object comprised of a header and accessor keys: the header keys are the column values that will be presented in the table, whereas the accessor properties are the values used to match up and build out the table from the stateful data objects passed as props from the main player/team detail component that creates some of the presentational elements that represent the details view.
The other core elements of building out the table is the use of react-table specific hooks to construct the data view. One of the core problems is the potential for significant mapping through the data elements for each accessor value, hence the use of the react useMemo hook, to ensure that data isn’t recalculated on every re-render if the data doesn’t change, in the case of moving from one player detail view to another. The process of each table being generated is the sum of passed props into the table component, making them truly reusable because, react-table itself isn’t a UI component in of itself, but a declarative utility library that gives complete control over the table generation process using the table instance variables decomposed from the useTable hook. One of the few problems that occurred in constructing the tables is the that the table data passed as a prop into the table component code, returned as undefined. This was a result of react-table expecting an array of objects. While the state being passed is implied to be an array, react-table requires it be declared explicitly, as such whenever player or team data is saved to state, that useState must be initialised with an empty array within the parameter block. 

	Sprint 5 – Data Visualisation Views. 
The bulk of research and development time over the course of this project was spent on the themes of constructing dynamic visualizations, that in the future, would be exportable and saveable as user generated content. There are three distinct approaches I took that I felt captured a significant distribution of available NBA data: direct player comparisons, team comparisons and shot charts. Regular season because games played and data points created are standardized: Every team will play the same number of games (82) unless, the season is shortened due to lockouts. 
In most cases the data being visualised for players are using the same endpoints that create the stateful data for the previously discussed table components, however the manipulation of said data is what has changed the most. For teams, numerical and graphical analysis necessitates the creation of new endpoints within our proxy, grabbing year by year statistics for NBA teams. The shot chart, the most complex visualization within this application, also has a dedicated endpoint create within our proxy to serve up the relevant geolocation data.
	Player comparison visualisations
The creation of the two main player comparison views required the development of two core components, a miniature analysis dashboard for player and stat selection and the visual chart component to process data and render a canvas that presents our data (canvas is the html selector through which both chart.js and d3.js can display visuals). 
Due to the core nature of the react ecosystem and the implementation of a virtual DOM, issues with chart.js emerged immediately. The standard library requires direct access to the DOM through a document selector and passing a reference to the chart type. This however is negated using the wrapper library react-chartjs-2, which then only requires the registering of certain chart.js functionality that has been pulled from chart.js using destructuring syntax. After this procedure is carried out, the core chart resembles other JSX components within our application. 
The analysis dashboard is a relatively simple form component comprised of searchable ant design-selector components. This solution to the selector allows for searchability and default values to be saved to state. There are two instances of this dashboard, one designed for single statistical comparison and the other with an additional statistic selector to measure evaluate the relationship between two statistics. The values selected from our bars are passed as props down to the separated graph components. For our single statistical view, for each player, two calls are made, one for the player seasonal data and one for basic information. Player seasonal data is called using the redux toolkit generated hook, as it’s a common one used across the entire application, whereas the API is designed to load a player’s simple information is using axios. Each call is then processed to extract and save seasonal data within a useState field.
Two key problems arose in creating the API calls for both the SAS and TSA components. Firstly, the initial problem occurred on the component render cycle: the props, such as player IDs to pass a parameter to API calls and the select statistic being targeted for analysis where initially only set when a value was actively selected from within our fields, meaning that on render, undefined values being were being passed into the relevant chart component from each dashboard, and as a result API calls where throwing errors. While this didn’t present any breaking changes to the view of our analysis pages, unnecessary API errors was a bug that still needed to be solved. The solution to this problem was simple: initializing the useState fields for each player with an active ID from our playerJSON file used to provide options within our select components. 
The second major problem though occurred again, because of the render cycle, rerunning whenever a prop or stateful data changes within the component or view. Because we are making eight sequential API calls, we ran into rate limit issues with the stat.nba.com API. Effectively, the proxy routes were receiving requests and proceeding to them on to the actual API, (this was done to avoid previously mentioned cross origin issues), but the API has a limit of how may requests can be sent per second, and as such responses weren’t being issued by the API. The resolution to this including an empty dependency array that will limit each useEffect hook and the asynchronous API calls to run once per render cycle instead of multiple times. 
Aside from the challenge of managing the data state within the application, ensuring data was loaded dynamically was a key concern. Related tooltips and labels needed to be updated to reflect the change in the relevant player selector and the player ID that was being passed into an API call. To accomplish this, the creation of player objects for each of the four players to hold key values required for both data presentation and tooltips was required. 
One of the core benefits of chart.js is automatic dynamic interactivity when graphs are created without the need for additional code. But since data is usually declared when a graph is created and isn’t unknown, we had to adapt the approach taken. Two factors determined what the graph would visualize: the stats picked from dashboard component as well as the player data loaded from API calls. To extract the chosen data points, we needed to pass the chosen statistic into a map function as a string literal, mapping over each season in the object array, finding the key that related to our chosen statistic, and pushing the value of that key into the respective player object stat array.  
Figure 7: code snippet detailing the method used to build specific arrays of chosen stats for playerOne
This method enabled chart data to change depending on the metric that was chosen in the dashboard.  There was however some issues with some related features not shifting depending on which player was chosen. API data that needed to be rendered as html such as graph titles didn’t respond unless the prop that determined their value, player IDs, were passed as dependencies to the related API calls, our seasonal data responded accordingly because redux toolkit manages this without additional code, but a useEffect axios calls required the additional dependency variable.
While a significant portion of this section is devoted to both the single and two stat visual components, there exists a slight difference between the two in the approach taken to build the metrics arrays being passed as data into chart.js. Single stat requires only one variable because of it being a line chart, comparing players over time, but the two stat variable is designed to measure the relationship between two variables, hence the use of a scatter graph that required an x and y variable to build. As a result of this interaction, instead of constructing a single array to be passed in each explicit dataset, we needed an object array. The method use is detailed below: 
 
Within the two stat analysis view, two data selectors are passed as props, and this helps those change the data being piped into chart.js. 






 
 

 



Bibliography
[1]B. Anthony, "KenPom 101: What the college basketball metric system is and how it ranks Michigan", MaizenBrew, 2021. [Online]. Available: https://www.maizenbrew.com/2019/10/23/20928669/kenpom-explained-what-it-means-michigan-basketball-ranking. [Accessed: 13- Nov- 2021].
background: rgb(255,255,255);
background: linear-gradient(90deg, rgba(255,255,255,1) 7%, rgba(252,176,69,1) 85%, rgba(252,176,69,1) 99%);

 
HARD TARGET = 17000 words!!!!!
