It could be argued, now, more than ever, that data is the central pillar on which the modern world rests upon. Everything from critical energy and food systems, supply chains that keep as warm and fed, the games and television shows we consume are created, implemented, and maintained using a data-first approach. The reasons are varied of course: in the case of television, data allows for greater strategic planning, creating experiences which target a key demographic, with a certain spending habit to best extract value, by plying these groups with the shows they want to watch. In the healthcare field, data allows medical personnel to tackle key problems that might lead to policy changes: the battle against obesity, high blood pressure, diabetes and heart diseases are all waged using a data-driven approach: Find connections between certain ailments, cluster effects and propensity to occur due to the demographics of a region. 
The digital advent that has occurred over the last two decades has done nothing but accelerate this process, creating vast repositories of information, mostly without concern for the implications on the assumed right to privacy. The effort to acquire data, especially at the consumer level, has spawned organizations whose entire purpose is the acquisition of individual data, to sell to companies who wish to target consumers with ads based on their taste, conveyed through the information collected by technology and social media sites like Google, Facebook, Instagram, Amazon, and so on. And while there is an appropriate concern for the implications of such mass data mining, it can also eb said that the benefits have been immense: the creation and redefinition of entire fields such and the roles within them (Data Scientists, Analysts and Engineers) and the economic benefits and scientific advances that it has conferred being chief amongst them.
There are no fields that hasn’t been altered by the ascent of the big data age: Data in sports has always held intriguing potential, for its ability to look beyond the action on the field and unlock potential within individual players, teams, and organizations with the long-term goal of achieving greater successes, building dynasties, or even returning to relevance. Some Basketball teams within the National Basketball Association, over the course of the last two decades have taken it upon themselves to adopt an increasingly data-driven and statistical approach to the game of basketball, innovations made possible by new innovations in computer vision, software, and hardware engineering. Franchises within the league have taken it upon themselves to building new software platforms that take the wealth of visual and numerical data generated to build new models that have informed coaching decisions. 
Principle examples of this mode of thinking within the league have been championed by the San Antonio Spurs, Golden State Warriors and Houston Rockets, moving away from a heavier isolation and post-game heavy style of offense, to 3-and-out, rim running style prioritizing 3-point shooting as it has a higher expected value per attempt, and close range lay ups for higher frequency of point generation and second chance scoring opportunities. These insights were made dude to the new statistical approach of viewing the game whereas prior generations of coaches and players relied on the individual talents of star teammates and direct coach-led offensive schemes to generate scoring opportunities.
All these innovations in sports (In our case the game of basketball) are possible to a mix of hardware and software innovations that have taken the great many tables of data produced by scorekeepers over the history of the game, to provide tangible insights to drive the NBA forward. For this thesis, I have looked at the tools, websites, and software available to NBA fans who might lack the analytical or statistical skill to breakdown tables or lack of access to the same software that NBA franchise use to create their insights.
	 Aims and Objectives.
The goal of this projects is to create an MVP (minimum viable product) web application with modules capable of:
	loading information about NBA players and teams
	dynamically generating sortable tables of basketball statistics
	Allowing these tables to be used to create Data visualisations
	These visualisations need to be saveable to a user account for further editing or downloadable to Hard disk.
	This Functionality necessitates the creation of a login system to allow enable the ability to edit and retrieve visualisations created. 
Achieving this would require a comprehensive review of the various Software tools available to us: Programming languages, web frameworks and third-party application programming interfaces (APIs). The MVP is the lowest level deliverable required to achieve some the desired goal of allowing users to create visualisations on basketball statistics. However there also exist some higher-level goals for this project:
	The creation of a statistical engine on the web platform to conduct various statistical tests on the Data.
	Animation of Play-by-Play and player tracking Data, visualising game action that leads to scoring events. 




 
	Background and Context
Prior to any discussion or consensus on the development of the application, its important we ground ourselves in the historical background of the NBA and the use of statistics and data over the course of said history. Its also important to note the effect data and its visualisation has regarding the storytelling within the confines of the NBA. Furthermore, its crucial to understand the user of this app and the state of the field regarding the other tools and websites that may or may not facilitate some of the functionality that our application strives to accomplish. 
	The User
There is significant importance in creating an application that suits the needs of its users, however there is some base knowledge of the game of basketball required to fully appreciate the use case for this application. Therefore, this isn’t an app made for the public, but those with a slightly more nuanced view of the game, starting with the more casual fans to those enthusiasts with a desire for a more analytical understanding of the game of basketball, creating, and forming narratives from the data and visualisations created within the application. These fans can be found in great multitude on the internet, frequenting forums, and chat rooms, connecting with each other from across the world, a testament to the global reach and appeal of the NBA. One of the largest online communities in which basketball debate takes place is the Reddit community r/NBA. Reddit, one of the most visited websites in the world, has many community subreddits, catering to the many interests’ people have, with the NBA subreddit being the second most subscribed to sports subreddit, numbering 4 million with 10s of thousands of daily readers. Online engagement with these fans and NBA watchers is the demographic that would best represent the type of user the application is targeted at. 
 
	Context on the NBA
The NBA, if anything, could be considered a game of superstars. In few other team games is it possible for one star to lift their team from the doldrums of mediocrity to championship heights. There are palpable effects on stadium income and game attendance when a superstar is present vs when it’s absent, Kaplan estimates a 7.25% decrease in ticket prices, which in the case of an injured star, is a loss that can compound over the course of a season resulting in ticket revenue losses in the millions. 
Therefore, regardless of the various evolutions that have occurred since the NBA’s beginnings, from the increasing sophistication of on-court play, rule changes, game management, personnel training, and monetary valuations, the adage that basketball is a game of superstars holds true. It's through this veneer that we can divide the eras of the sport, and how the analysis of basketball has changed as a result. It’s important to understand the history of the NBA to some extent because it best explains 


	The Classical Era
The early era of the NBA could be counted as a period encompassing the founding of the NBA to the establishment of the three-point line. This was invariably the era of the big men: Towering centers who ruled the game from the post or under the basket. Arguably the leagues first true superstar, George Mikan dominated the earliest era, towering over his competition and leading his franchise, the Minneapolis Lakers, to five championships in 6 seasons, the leagues first dynasty. Bill Russell was the leader and defensive anchor of the greatest dynasty in sports history winning 11 championships from 1956 to 1969 and 5 Most Valuable Player awards during that Span. Wilt Chamberlain and Kareem Abdul-Jabbar, immense dynamos on offense and defence, setting records that stand till this day. While there was no shortage of excellent perimeter guards or forwards such as Oscar Robertson, Elgin Baylor and Jerry West, all hall of famers and NBA legends, this was in arguably the era of big bruising 7-foot players. This fact is represented in the awards handed out during the classical era: from its inception to 1979 the NBA’s MVP Award was awarded to a center 20 times, whereas guards and forwards combined for 4 during that same span. 
It’s in this era where we can see the effect a superstar can have on league policy. Mikan’s overall greatness forced rule changes that helped define the current state of the game, Firstly the advent of the shot clock in the aftermath of the Minneapolis Lakers versus Fort Wayne Pistons in 1950 led to the lowest scoring game in league history. The 24-second shot clock was an innovation that led to faster pace of play. The other innovation that could be attributed to the dominance of superstars is the creation of the “key”, the expanding the space around the hoop, drawing it out further to limit the scoring potential of post dominant players like Chamberlain, Mikan and Russell. Goldsberry directly attributes the current lane size to Chamberlain, as well as the concept of “offensive goaltending” and free-throw rules. 
While the classic era laid down the foundation for the current game regarding ruleset and player impact, it was a rather weak time for the games statistical timing. The game only officially counted core stats, points, total rebounds, assists, field goals attempted and made, free throws attempted and made as well as personal fouls. Blocks and steals weren’t counted until the 1973-74 season, the 28th in NBA history. Advanced statistics and analysis weren’t yet in vogue. 

	A Transitional Era (1980s and 2000s)
The advent of the three-point line, a holdover from the American Basketball Association (ABA) which had recently merged with the rest of the NBA, marks the dawn of the games modern age. While all save the most legendary players of the classical era have had their careers diminished by time, it’s from this point forward that the NBA’s superstars become cultural mainstays. This era saw the rivalry between Erving “Magic” Johnson and Larry Bird redefine the NBA of the 80s, against the backdrop of racial tension in America, and reintroduce the game to America, after 70s troubled by on-court violence, start-up leagues and drug issues. The 80s also introduced Michael Jordan, drafted with the second pick to the Chicago Bulls, who in the 90s would become the greatest of all time leading his Bulls dynasty to 6 NBA Championships in 8 attempts. Other notable superstars during the modern period would include Tim Duncan, Shaquille O’Neal, Kobe Bryant, Tracy McGrady, Vince Carter and Dirk Nowitzki all of whom would emerge in the later 90s and early 2000s. This period saw the intense internationalisation of the game, and an increase global appeal, driven again by the superstars of the league. 
This era sees the acceleration of the stylistic shift induced by the creation of the three-point line, moving away from under-the-basket, post centric style, allowing smaller and more ranged based players to shine, utilizing mid-range and three-point shots. The biggest motivator of this shift, as always are the popular stars that excelled at this type of shot profile. Michael Jordan’s sheer marketability, popularity, and style (a style that epitomized the aforementioned stylistic shift) meant that his on-court tendencies where emulated by the likes of Bryant, McGrady and Carter, and to a smaller extent Nowitzki. However, the game still had a place for offensively and defensively skilled big men in Duncan, Garnett and O’Neal. 

	Development of the Analytics Field in Basketball  
While advanced analytical perspectives emerged over the course of NBA history, the movement as we know it was deeply influenced by developments made in baseball, the field of sabermetrics and by the Oakland Athletics, a team that ushered in a data driven approach to their own game, leading to a record 102-win season in 2002 one of the lowest salaries in baseball, by picking up undervalued and underutilized players. Terner notes baseball’s owns sabermetric approach to constructing a team was crucial to the early work on basketball metrics written in the early 2000s. 
Dean Oliver’s Basketball on paper initially moved the needle away from per game statistics to that of a pace-oriented approach, how much could be accomplished in a set number of possessions, or set number of minutes, such as per 50 possessions of per 36 minutes. Oliver also pioneered the four factors: data driven axioms that correlate to a higher chance of winning. He created values such as turnover rate, effective field goal, offensive rebounding rate and free throw rates, which all trend higher on winning teams, and applied relative weights on each of the factors so they can a raw percentage chance of determining success. These factors are used by team front offices to determine relative performance against opponents, and as part of drafting strategies. 
 Another early pioneer, John Hollinger, introduced a new statistic that sought to estimates a player overall impact on the game. Player Efficiency Rating (PER), a metric that takes advantage of every variable in the box score to estimate players effectiveness. This was first of an emerging group of advanced statistics that seek to measure the overall player impact and efficiency, refining the methodology to resolve perceived flaws in pervious versions of prior performance statistics. By 2009, there was a consensus around the NBA that deemed that better tools where needed for cogent analysis of players whose box score stats, and hence box score derived analytics where subpar, yet held significant influence over the outcomes of games played. This realisation helped speed up the development on team statistical departments when Roland Beech, a stats guru 
 Examples of the increasing growth of the NBA analytics movement include the emergence of new personalities such as Ben Taylor, author of Thinking Basketball, Kirk Goldsberry, NBA Analyst, and author of Sprawlball. 
Beyond the numerical and statistical advances made over the earlier parts of the 2000s, a significant driving force of the current analytics movement is the dawn of player positional tracking and the creation of play-by-play data derived from inputs from player tracking cameras. The NBA was the first sports league to include SportVU cameras in each of their stadiums (Post-2016 the NBA has since transitioned to Second Spectrum). The effect of this drove demand for data professionals to create new insights into offensive and defensive possessions, team flow and on-court tactical strategies. 
The biggest effect of the data revolution has been an immense acceleration of the stylistic shift mentioned in section 2.2.2. Teams like the “7-Second or less” Phoenix Suns and the 2013-14 San Antonio Spurs served as early signals of the near total elimination of post focused play into the more pass first, 3 point or layup oriented up-tempo offense. But the team who have perhaps showcased the most from an analytics-driven approach to basketball is the James Harden era Houston Rockets, whom, led by an early advocate of analytics in General Manager Daryl Morey, saw an era of consistent competitiveness, historic and record-breaking offensive production, and personal success for James Harden, culminating in the 2018 Most Valuable Player. 

	Fan, Team and Media reactions to the analytics movement. 
A quick note must be made on the cultural impact of the movement amongst fans, teams and media personalities within the sport as their so acutely connected. Data driven insights early on had a great deal of detractors. Historically speaking, the measurement impact or the quality of a player, whether good or bad, rested on a concept colloquially called the “eye test”, essentially a set of long held values within the NBA that a players quality rested on factors like “clutch gene” or grit or whether a specific player was a “baller”. Some feared that analytics would drive excitement out of the sport and that teams would simply implement strategies deemed most effective on paper. NBA legend and hall of famer Charles Barkley famously derided analytics, likening those who choose to look at the game from its perspective as talentless people trying to force themselves into the NBA ecosystem. 



	Project Uniqueness and Existing Applications
The idea of a sports-data website or app is not unique, especially in sport as popular as basketball. It’s something that’s been done to varying degrees of depth and professionalism. Seeing as there are two aspects to this project, the gathering and presentation of raw data, and that data’s visualisation and analysis, it stands that we must evaluate the state of the art of basketball applications to determine whether anything new is being proposed by building this application. The first aspect, the creation of tabular data regarding NBA statistics is common and well operated. Arguably the most important of these websites is the official NBA Statistics page. There we can find tables of data for every player, team and game reaching back to the origin of the NBA. These tables exist for both the basic and advanced stats generated by NBA play as well as shot location data that’s used to build its patented shot charts. Another example of this type of website is basketball-reference.com, sourcing its initial data from sport data APIS like SportRadar. It too provides the same view of data as the official NBA stats page, tabulated, here however the data is exportable in a .csv format for those with a deeper understanding of programs like Excel to build out graphs and tables. 
While there are other smaller applications that serve the purpose that both these two major sites represent or are equipped within a degree more of functionality (theScore also takes account of betting lines and digital communication between fans during live games) the second major section that our app represents, the visualisation and analysis of data is far less common. From a purely software-based perspective, there are few applications or websites freely open to consumers that over anything other than surface level comparison between player data and teams, and outside of shot charts, programmatically create visualisations of this data for consumption. Visualisations regarding NBA statistics are still mostly created outside of a web application using Excel, R, Python and Stata or some form of proprietary software not available to the average fan. This absence of easily accessible data is compounded by issues like the lack of official documentation of the official NBA APIs (stats.nba.com or data.nba.net) or lack of personal access to SportVU or Second Spectrum visual data that records NBA player actions of in the court. 
As such, the design space that this app is operating in is to create NBA data visualisations of player and franchise statistics using a web-based platform, is relatively unique even if it contains elements of other websites such as tables to select data for use or shot chart generation for export. Furthermore, the two major sites we looked at don’t offer the login/graph load and save functionality that is being constructed within our application.






	Data in the context of the NBA
 
 Figure 1: Los Angeles Lakers basic box score vs Milwaukee Bucks on the 17th of November 2021
The breakdown of data within the NBA stretches numerous dimensions. At the lowest possible level exists the box score, quantitative and discrete (in so far as it’s a numerical measure whose accuracy cannot be improved) data points that capture various game actions: scoring, rebounding, passing, stealing, or blocking the basketball, effectively serve as the base level of data regarding player performance. An increase in any of these values denotes a positive action taken by a player within the game, such as scoring to push your teams lead, or getting a steal or block to deny a potential scoring possession by the opposing team. Rebounds can go two ways, an offensive rebound resets the possession for the attacking team, adding time to the shot clock and allowing another attempt to score, whilst a defensive rebound ends the opposing team’s offensive possession and can often lead to a “fast break” a quick and hard to defend scoring opportunity.
Within the context of the box score there is also data types that indicate negative actions by players. Turnovers, either forced such as having the ball stolen or deflected, or unforced like bouncing the ball out of bounds, are negative actions that end a possession (a chance to score). Personal fouls, which lead to a game stop and can, if a certain number of fouls are drawn, mean that players on the opposing team can shoot free throws to accrue more points, effectively making a negative action a positive gain for the opposing team. The box score also encompasses scoring metrics based on shots taken and shots made for the three shot types: Field goals, three-point and free throw attempts. Other miscellaneous box score data points also include minutes played in a minute-second format (MM:SS) as well as plus/minus data point (+/-), which is 
Advanced statistical data then, is derived from equations performed on basic box score data, in combination of relative weights applied to the relevant statistics. Whilst the typical box score seeks to provide as single instance data point on the events that occur within a game, advanced box score statistics are an attempt by their creators, media personalities and fans to mathematically discern a player’s impact beyond counting stats. Therefore, whilst calculating a largely quantitative task, it also serves a descriptive, qualitative purpose. Examples of advanced stat formulations can be seen in the way we calculate Player Impact Estimate (PIE), which again takes advantage of the entire box score can be denoted below:
(PTS+FGM+FTM-FGA-FTA+DREB+OREB/2+AST+STL+BLK/2-PF-TO)/(TPTS+TFGM+TFTM-TFGA-TFTA+TDREB+TOREB/2+TAST+TSTL+TBLK/2-TPF-TTO)
This formula takes each players individual contribution to the game while dividing it by total game metrics. Beyond overall player impact, other advanced stats seek to provide significant insight into a specific aspect of the game where box scores stats fail to elaborate. Shooting in the NBA at the elementary box score levels are separated by shot categories with shots made divided by shots attempted, but advanced stats can offer deeper nuance and help curate a narrative on whether a player is particularly effective at scoring. True shooting percentage is an advanced statistic that considers every shooting statistic to measure overall shooting efficiency: 
TS%=PTS/(2(FGA+(0.44*FTA)))
The final type of data that is prominently utilised is spatial-temporal player tracking data. As mentioned in section 2.3, the NBA in the early 2010s installed various specialised cameras around NBA arenas to build exceptionally more detailed play-by-play data sets than the basic versions that started to appear in the early 2000s. modern player tracking allowed for a finer level of details when it came to move set classification. A score was no longer just a differentiation between a 2 point or 3 point shot but whether or not the two points where acquired by layup, dunk or mid-range jump shot, whether a three-pointer was on a “catch and shoot” where a player is ready on the 3 point line to immediately attempt a score  or a “pull-up three” where the ballhandler effectively attempts a shot with significant time on the shot-clock. Beyond move set classification, the player tracking era has been a boon to in-house analytics teams on analysing player decision-making and evaluating scoring scenarios due to the emergence of “expected possession value”. 
This concept was created due to on court location data, combined with an average weight applied to potential game actions that can ball handler can initiate. Macdonald further notes two important factors when estimating a potential game action, other players possess the same decision-making facilities vis-à-vis on court movement, the ability to get open to improve a team’s offensive profile during that specific attacking possession such as dropping your defender, setting a screen on the on-ball defender etc. It also worth noting that as the ballhandler and his teammates make decisions, their opponents currently on defence take actions that invariably decrease a possession’s value. This complements the second factor, that each potential action by the ball handler, his teammates and their opponents are modelled separately to create, and all this is therefore gives rises to secondary values derived from EVP. 
 
	Design Methodology and Development Considerations
Building a significant piece of software requires discussions on various aspects of the development process, from the approach taken for the design of the application, to details and tools that are planned for use within the process of development. 

	Approach to the development process
For success of this project, there must be some form the continuous iteration so that potential users can view and utilize the product and provide feedback. Therefore, a consistent alpha and beta version of the application must be made built using a agile process. An agile process, even when implemented by a sole developer, provides a clear feedback loop on application iterations, on what works correctly and whether they feel, as users, that the development requirements are being met. It also provides an avenue for constructive criticism, on what application features and components needs further iteration or if an adjustment must be mad (alteration or removal of certain requirements). 
To this end a target group of friends and family has been created to help keep the application grounded in the various requirements stated earlier in the introduction. And to this end engagement will include, viewing and critiquing major components and themes, user interface design and user experience issues such as visibility and accessibility. To do this, they will have access to a view of the application through localhost tunnelling or controlled demos over video conferencing technology like Zoom, Discord or Microsoft teams.  
	Design Philosophy
A quick note should be made on our broader design philosophy. User (or human centred design) is a thought process that embraces that idea that humans themselves are all designers and requires designers to empathise with problems faced by humans in the design space and utilizing them at every turn, beyond just documenting their reaction and thoughts on the state of the application and product use, such as involving them in the iteration process, brainstorming and prototyping. This also occurs while focusing on delivering the general set of agile principles beyond planning and design, which is completing development and the feedback loop that allows for the iterative process to take place. The merit of human centred design is obvious, that the future user should have significant influence is given seeing as this is a product in part designed for general use by basketball fans seeking a multitude of services from the app: A quick lookup of current NBA players an easy visualisation system for stats in the browser. There, however, exists some merit in approaching this from a purely product perspective due to the assumed difficulty that is apparent in some component design, namely the creation of a statistical engine for deeper mathematical view on the relationship between NBA stat variables. The case for every user being involved in a design process is weakened when there is a disconnect between their induvial (or even collective) vision for the application, and the technical skill and knowledge of the engineers having to implement it. Essentially, the application has to be grounded in a shared reality. 
Secondly a broader take on the implementation of agile processes within the scope of our project are in order. There exists a range of design approaches that take advantage of the iterative nature of agile development, there are also flavours of agile development that should be considered. One of particular interest that fits this project well is the use of Feature-Driven Development (FDD). A react app is defined by the components that comprise it, hence it cannot be considered a monolithic structure with mass interdependency from all aspects. The component-style structure of react apps lends itself to focused periods of development and sprints where an active feature is planned, designed, developed, and tested both independently and by focus group, looking for both positive and constructive feedback. Therefore, in a hypothetical app structure where we have a component dedicated to finding players which includes functions which: 
	Pull data from an Application Programming Interface (API) and save it as state
	Dynamically present the data use higher order functions
	Allows you to filter the presented data using a select field,
Keying each major view and the component involved in the building of said view could, foreseeably be done well in an FDD format. Other benefits include rapid adaptability to the changing design requirements, per the iterative format and reliance on user feedback in the agile design process. 
 There are of course some detrimental elements to the use of any agile method. In the case of this application’s development, one such detriment that should be mitigated against alludes back to the point made on human centred development: which is the need to include users at every stage of the development process means less time building the project and more time managing feedback and opinions created by the presence of users. This overreliance on the processes that deliver information on the whether the application is meeting requirements does imply a certain disregard to the product design and architecture processes that ensure that help ensure an applications overall design cohesion. 
Agile also presents a certain risk to overall application cohesion. Its nature of rapid, iterative nature can mean shortcuts taken which in application development means external libraries that shorten development time. Thus, any change from the iteration process that means suggests a removal or adjustment of certain components could mean time spent refactoring and rebuilding already existing functionality using a newer library. Effectively there may be a need to account for the trade-off between refactor old components and the development of new functionality. It also serves to remind us of the potential for exploding complexity that might occur due to choosing prebuilt and documented solutions to some issues (such as data fetching, of which there are multiple approaches that will be discussed in detail further below). 


	App Design and Architecture
From a design perspective, there is merit in constructing a view on how a user will use the application, a user journey through different web views and components, using paper and digital mock-ups of the website as a test bed for users. The architecture of a web application and page flow can be demonstrated in multiple different ways: A top down, stack driven architecture that displays the actual tools and request flow in and out of the frontend view through the middleware to the backend. Optionally, we can evaluate architecture in more detail on a component level, seeing what data is fetched and where. 
	App Design.
Design is one of the few areas where the agile process has its most influence, guiding an application from mock-up to MVP to a production ready webpage highlights the effectiveness of the iterative process. The images below present the core web views and components required to achieve construct an MVP product. 
The mock-up details the application flow from the perspective of a parent view to that its child component. The first details the player section flow: 
 
Figure 4: Player Section Mock-up
Page navigation is rooted in the nav-bar component which routes to the other staging points within our application. The navigation from the player finder view to the player detail’s view is predicated on the selection of either a prerendered player card (an accessibility tool for those who lack knowledge of NBA athletes) or the search bar which contains all current NBA players.
The same view flow can be established for teams to team details flow, from the nav-bar to the team cards containing core team details (name, conference, wins and losses), then leading to the team details page, with broader information, team roster with stats via a table and previous games log. 
The analysis page is distinct in the fact that its accessed directly by the nav-bar and is comprised of one smaller card element containing the settings to which to construct a visualisation with the ability to add and remove players, toggle stats for direct comparison using a line chart (for the MVP). The larger card is responsible for the rendering of the chart to the view. 




	Core Programming Languages and Tools
Software development is replete with a variety of tools that can enable the production of any sort of application or data analysis/ visualisation. The advantage of choice allows us to analyse the various technology stacks and whether the tools within them can allow us to construct what our application needs. As our application is primarily web and desktop based, we can leverage features like more powerful computing solutions and larger screens to create a strong, visually appealing web application. This section will be concerned primarily with the core tools/ecosystems that will be critical to development. Some minor packages will be discussed further in the section 4 where the discussion of the application construction takes place. 
	Frontend Development
ReactJS serves as the frontend library of choice here. Built and maintained by Meta (formerly Facebook), its declarative, making it easier to read and write code. React also benefits from the use of a virtual document object model (DOM), which over the conventional DOM, has significant memory, speed, and performance benefits over traditional HTML and the standard DOM. ReactJS utilizes JSX, or JavaScript Extensible Markup Language, allowing the co-existence of HTML code snippets and JS syntax to help produce user interface elements. ReactJS’s largest advantage over the traditional static HTML/CSS combination is it allows the creation of reusable components in which we can pass parameters called “props”, that help build further component functionality. 
While React is effective as a UI library it is relatively barebones compared to fully fledge frameworks like AngularJS; as such we can take advantage of the JavaScript toolchain, Node Package Manager (NPM) to add new libraries that help implement new functionality such as React Router, which allows for dynamic page routing around the application, and keeping some views and components unrendered if authentication requirements are not met. Other libraries offer pre-built components such react-bootstrap, which allows for responsive elements taken from the standard bootstrap library to be used in a React context. While this functionality isn’t limited to React apps, the advantages of this is far quicker MVP creation and turnaround on feature creation, something that suits the agile approach application development is taking. 
These react tools are a significant element of this application as many are involved in the construction of the various components that comprise the app.
	React Router, a declarative routing library that allows for the linking of our various components together without refreshing and is key in the construction of any react application. 
	Ant Design, another component library like react-bootstrap, but with a broader focus on sleek design templates
	React-Table, a utility class for the design and implementation of robust tables using custom hooks provided by the library

Beyond the interface scaffolding and UI building properties of React, we will be taking advantage of Cascading Style Sheets to customise the look of our components. The earlier project proposal suggested the use of SASS (Syntactically Awesome Style Sheets) but it has been an unnecessary addition to the project. 

	Charting Libraries.
An oft repeated central objective of this application is the dynamic visualisation of data, a task that is served by frontend components. There are two options, D3.js and Charts.js. 
D3.js is a library designed for the presentation of data on the web through binding data to the DOM, and the application of graphical transformations to create unique graphs. As such, d3 doesn’t follow a template method, where certain types of visualisations are already created, therefore any type of visualisation must be defined with client-side code, making it more verbose but far more powerful than a templated solution. D3, being purely client-side, eliminates the need for back-end communication except in the case of data requests required to deal with data. There are however some nuances to using D3 inside of a React application. D3 targets the DOM but React apps are implemented through a virtual DOM, so D3 must interact with the virtual DOM through references to a virtualised JSX container element, which will serve as the building blocks of any visualisation created. 
Chart.js then, is a template driven charting library, that comes complete with 8 common graph types. It is inherently less powerful than D3. But its simpler implementations mean we can take advantage of props to transfer data to pre-built charting components to quickly render a new graph. There is also no DOM/Virtual DOM conflict between it and React, meaning there’s no compatibility issues. So, two use cases emerge from both these charting libraries. Chart.js is suitable for a significant portion of our applications needs from simple graphs showcasing basic NBA counting stats, to two variable analysis of NBA player variables like three-point shots and three-point makes. D3 is far more suited to more complex or esoteric visualisation needs, in these cases building NBA shot charts, a visualisation that is uniquely different for every NBA player. 

	Backend Development
While frontend development in the case of this application is a relatively integrated affair, with a React app and JavaScript toolchain that makes adding required packages and libraries trivial, and a similar ecosystem all based around the same language, backend development is often more modular, with different services been required for different duties. Two set duties required of the application is data fetching which, can and is often carried out in the client side of an application, in this case requires a combination frontend/backend solution, through a request library. Secondly, application requirements require that the app must be able to login and save images over the internet, therefore we require a backend solution to this as well. As such, we have identified three services that need to be constructed for the goal of the proper functioning of this application. 
	Firebase Authentication and Database. 
The authentication layer of the application will be implemented with Firebase, a backend-as-a-Service (BaaS), utility to comes complete with hosting, security and database services and provides us with significant boilerplate code to hasten the creation of typically complex features like an authentication layer, which matches well with agile development philosophy. There was also an exploration of an express.js and mongo database approach to authentication that will be analysed in the implementation section. 
	REST APIs and Data Sources. 
Data as previously stated, is at the core of this project and sourcing it is of major concern to the backend implementation of this application. There are multiple REST APIs available for consumption by the application and while they each have their merits and drawbacks, I ultimately handled data using 3 core APIs. The REST protocol or the Representational State Transfer protocol is an architectural style for distributed media systems, that contains a uniform approach to the request and acquisition of data over a HTTP network. 
The first of the APIs we explored in the construction of this application was those located on the RapidAPI platform, API-NBA and Free NBA APIs. API-NBA offered endpoints on a lookup of current NBA players, and their performance through major statistics, as well as access to some media options (team icons and player headshots). Beyond these benefits however, they were scarce on many data points that would be required to build a robust data visualisation of any merit. They lacked detailed game logs (which as contains advanced statistical data) as well as play by play information, and as such while they may be beneficial for some presentational elements, they couldn’t truly anchor the data visual element of the application all too well.
The second major API considered for this application included the Sportradar NBA API. Sportradar, serving as the NBA’s official data partner, contains a host of powerful endpoints that included play by play data, and some location data, (important for the implementation of a shot chart visualisation). However, there were limitations. Large scale deployment requires thousands of API calls, and the Sportradar API only offered small, individual applications a trial that only permitted 1000 calls a month. Such rate limitations make it impractical to deploy. Beyond this there were some technical problems that would be elaborated upon during the discussion of the application development. 
The API that was selected for the core of this application, was the unofficial NBA API, maintained by the association. There are two resources that are published by the association: stats.nba.com and data.nba.com. Only data.nba endpoints are accessible within a web browser (in essence the same origin), while the other runs into cross site resource retrieval  errors (another point to elaborate on during the discussion on development), which ensures that access from a client-side application is impossible meaning the requirement of the implementation of an API proxy, a service that acts as a ferryman between user requests and the API endpoints and queries results. (Exploration of the stats.nba API and its endpoints as well as the construction of an API proxy is a significant development topic that will be fully explored in the relevant section). Its important to note that while we are relying on API services to deliver some data, some will automatically be rendered from JSON built using web and API scraping, for the sake of simplicity or static presentational components. 

	Python Toolset. 
Python (and its ecosystem) are the last significant element of this applications stack. Python is an interpreted, object-oriented language that ubiquitous with data analysis and visualisation, but also provides frameworks heavily employed within the technology industry for web and API development. Its alongside JavaScript, allow for quick turnaround times on development and implementation cycles. Of the framework and libraries available within the ecosystem, Flask is a lightweight “micro” web framework to build backends and APIs, helping to simplify API request and response routing and dispatching, and possess the same philosophy of the react eco system, an inherently light tool that can be extended through additional packages. 

	State Management.
The complexities of modern web application development are accentuated by the significance of state management problems that arise whenever a relatively robust or data heavy component-based application is created. The concept of state itself is opaque, but within his context, it can be distilled into a simple premise: State is any data that helps shape in-moment behaviour of the application. 
Specific types of state can include communication state, which manages the flow of information to and from various services, which are yet to be completed, UI or application state, which is the state of component elements within an application, whether a certain component is selected, whether a form component like an input or select has any value and storing said value. There also exists session state, differentiating between who’s logged in and communicating with backend services such as databases or cloud storage to deliver the account linked to the login parameters passed in. 
While this list is not exhaustive of the types of state that exist, they are the core types of state that will require development control over. Therefore, state management as a whole is the task of ensure fidelity of state over time and through changes, ensuring that state read and writes (lookups and updates) are coherently and correctly handled and this is accomplished, in the Context of React, through a myriad of techniques, and frameworks.
As such for the purposes of this application, most application state can be handled using either React hooks, a newer feature of React 16 or the popular state management library, Redux and Redux Toolkit, which enables simpler code practices in setting up data stores and services to manage state across the application.
 
	App Architecture
The diagram of how each of the above components interact within the project is laid out below: 	

React Router and Redux encapsulate every component within the application, with Redux acting as a global store allowing for state to be passed to every component via react hooks, and the router allows page/view navigation within the application. 
API calls are managed 

	Application Development. 
This section concerns itself intricacies of the development process of the various components and views that make up the application. This section will also go over problems and alternate approaches I pursued to build key elements of this application that were phased out for another, simpler solution. 
	Sprint 1 - Enviroment Setup. 
The application architecture presented above requires the decoupling of the 2 major portions of this application. A decision was made that the first task should be creation of our base directories for both the flask API proxy server and react application base using the create-react-app command line interface (CLI) and to install the various dependencies required. 
The initial problems of installing Python for use for our proxy server served no problems however, a common issue exists with the installation of libraries in the base python directory for use. Sometimes integrated development environments are unable to detect their installation making calling them difficult. Hence the first major package required of this Sprint cycle was the use of venv, a library that creates a virtual environment for the python installation of your choice. This offers programmers granular control of what packages exist within this environment, which acts as almost a fresh installation of python, hence anything installed here doesn’t get installed at the overall system level, leading to less system pollution 
Secondly, packages in this environment are more easily retrieved than importing from packages from the system site level, which as before, occurred at the start of project. Finally, there exists the capability to freeze dependencies, due to the encapsulation of your packages, you can run a custom command to create a text file of every package used within a virtual environment and use that requirements.txt file to create those environmental conditions on any machines. 
Setting up the react application as previously stated required the use of the create-react-app CLI , which comes installed with node modules, underlying libraries that power the react ecosystem. Automatically installed alongside react core dependencies include 
 


Bibliography
[1]B. Anthony, "KenPom 101: What the college basketball metric system is and how it ranks Michigan", MaizenBrew, 2021. [Online]. Available: https://www.maizenbrew.com/2019/10/23/20928669/kenpom-explained-what-it-means-michigan-basketball-ranking. [Accessed: 13- Nov- 2021].
background: rgb(255,255,255);
background: linear-gradient(90deg, rgba(255,255,255,1) 7%, rgba(252,176,69,1) 85%, rgba(252,176,69,1) 99%);

